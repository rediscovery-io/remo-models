{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFu86xZfsX9M",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Installation\n",
    "!pip install remo\n",
    "!python -m remo_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "EI72wutnsdyO",
    "outputId": "347b3820-f40b-4707-c6c9-666680d951fc"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import random\n",
    "import remo\n",
    "remo.set_viewer('jupyter')\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = remo.create_dataset(name = 'flowers-train',\n",
    "                    paths_to_upload=[\"flower/flowers/train\", \"flower/flowers/flowers_train_numeric.csv\"],\n",
    "                    annotation_task = \"Image classification\",\n",
    "                    class_encoding=\"flower/flowers/data_encoding.csv\")\n",
    "\n",
    "valid_dataset = remo.create_dataset(name = 'flowers-valid',\n",
    "                    paths_to_upload=[\"flower/flowers/valid\", \"flower/flowers/flowers_valid_numeric.csv\"],\n",
    "                    annotation_task = \"Image classification\",\n",
    "                    class_encoding=\"flower/flowers/data_encoding.csv\")\n",
    "\n",
    "test_dataset = remo.create_dataset(name = 'flowers-test',\n",
    "                    paths_to_upload=[\"flower/flowers/test\", \"flower/flowers/flowers_test_numeric.csv\"],\n",
    "                    annotation_task = \"Image classification\",\n",
    "                    class_encoding=\"flower/flowers/data_encoding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset 16 - 'flowers-valid',\n",
       " Dataset 17 - 'flowers-train',\n",
       " Dataset 18 - 'flowers-test']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remo.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = remo.get_dataset(16)\n",
    "training_dataset = remo.get_dataset(17)\n",
    "testing_dataset = remo.get_dataset(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_bb80997b-9ec5-4fc1-a95b-da7f5916ddd6\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/17?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_bb80997b-9ec5-4fc1-a95b-da7f5916ddd6\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_6696e631-1900-4600-b8fc-50cb816d744c\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/16?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_6696e631-1900-4600-b8fc-50cb816d744c\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_ba87813a-fce3-44e8-8baa-4283166ce0d8\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/18?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_ba87813a-fce3-44e8-8baa-4283166ce0d8\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Training Statistics [{'AnnotationSet ID': 9, 'AnnotationSet name': 'Image \"\n",
      " \"classification', 'n_images': 0, 'n_classes': 102, 'n_objects': 0, \"\n",
      " \"'top_3_classes': [{'name': 'Petunia', 'count': 206}, {'name': 'Passion \"\n",
      " \"flower', 'count': 205}, {'name': 'Wallflower', 'count': 157}], \"\n",
      " \"'creation_date': None, 'last_modified_date': '2020-07-10T11:11:33.708416Z'}]\")\n",
      "(\"Validation Statistics [{'AnnotationSet ID': 8, 'AnnotationSet name': 'Image \"\n",
      " \"classification', 'n_images': 0, 'n_classes': 102, 'n_objects': 0, \"\n",
      " \"'top_3_classes': [{'name': 'Petunia', 'count': 28}, {'name': 'Cyclamen', \"\n",
      " \"'count': 25}, {'name': 'Passion flower', 'count': 21}], 'creation_date': \"\n",
      " \"None, 'last_modified_date': '2020-07-10T10:44:32.055997Z'}]\")\n",
      "(\"Testing Statistics [{'AnnotationSet ID': 10, 'AnnotationSet name': 'Image \"\n",
      " \"classification', 'n_images': 0, 'n_classes': 102, 'n_objects': 0, \"\n",
      " \"'top_3_classes': [{'name': 'Water lily', 'count': 28}, {'name': 'Passion \"\n",
      " \"flower', 'count': 25}, {'name': 'Petunia', 'count': 24}], 'creation_date': \"\n",
      " \"None, 'last_modified_date': '2020-07-10T11:17:25.567423Z'}]\")\n"
     ]
    }
   ],
   "source": [
    "train_stats = training_dataset.get_annotation_statistics()\n",
    "valid_stats = validation_dataset.get_annotation_statistics()\n",
    "test_stats = testing_dataset.get_annotation_statistics()\n",
    "\n",
    "pprint(\"Training Statistics {}\".format(train_stats))\n",
    "pprint(\"Validation Statistics {}\".format(valid_stats))\n",
    "pprint(\"Testing Statistics {}\".format(test_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.export_annotations_to_file(\"training.csv\", annotation_format=\"csv\", full_path='true')\n",
    "testing_dataset.export_annotations_to_file(\"testing.csv\", annotation_format=\"csv\", full_path='true')\n",
    "validation_dataset.export_annotations_to_file(\"validation.csv\", annotation_format=\"csv\", full_path='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgrPCv6E8ipU"
   },
   "outputs": [],
   "source": [
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, annotations, data_path, mapping, num_classes, transform=None, mode=\"train\"):\n",
    "        self.data = pd.read_csv(annotations)\n",
    "        self.mapping = pd.read_csv(mapping)\n",
    "        self.mapping = dict(zip(self.mapping[\"1\"], self.mapping[\"0\"]))\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        labels = self.mapping[self.data.loc[idx, 'classes'].lower()]\n",
    "        im_path = self.data_path + \"/\" + str(labels) + \"/\" + self.data.loc[idx, 'file_name']\n",
    "        label_tensor = torch.as_tensor(labels-1, dtype=torch.long)\n",
    "        im = Image.open(im_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        if self.mode == \"test\":\n",
    "            return {\"im\" : im, \"labels\": label_tensor, \"im_name\" : self.data.loc[idx, 'file_name']}\n",
    "        else:\n",
    "            return {\"im\" : im, \"labels\" : label_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "1e193402cc1b4dbe97531c28ac93a8bb",
      "18d04c743bb4459d8a8235e8846b178e",
      "ec07bf4e45574e9ca39217f19a0adb48",
      "822d18ace03e4637892cf40ae0996e4a",
      "ca38e79005dd4612ae97645c53113ae2",
      "2690eec5fed040cd801e83c2f178d068",
      "b37da2626af94b649d19213f38e14d65",
      "403ac43de7454dd4b4dfdab3a61ffe14"
     ]
    },
    "colab_type": "code",
    "id": "lCxV4MgZ8fEs",
    "outputId": "325236d0-57df-49f3-b881-a81183de8559"
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.required_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(512, 256), nn.ReLU(), nn.Dropout(p=0.5), nn.Linear(256, 102), nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_usNSOE7Ao6n"
   },
   "outputs": [],
   "source": [
    "def train_model(model, data_loaders, optimizer, criterion, num_epochs, dataset_size):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    print(\"Training Data Size {}\".format(dataset_size[\"train\"]))\n",
    "    print(\"Validation Data Size {}\".format(dataset_size[\"valid\"]))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        print(\"Epoch Number {}\".format(epoch))\n",
    "\n",
    "        training_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0\n",
    "        correct_preds = 0\n",
    "        best_acc = 0\n",
    "        validation = 0.0\n",
    "        total = 0\n",
    "\n",
    "\n",
    "        data_loader = tqdm.tqdm(data_loaders[\"train\"])\n",
    "        for x, data in enumerate(data_loader):\n",
    "            inputs, labels = data[\"im\"].to(device), data[\"labels\"].to(device)\n",
    "            outputs = model(inputs)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = training_loss / dataset_size[\"train\"]\n",
    "\n",
    "        print(\"Training Loss : {:.5f}\".format(epoch_loss))\n",
    "\n",
    "        val_data_loader = tqdm.tqdm(data_loaders[\"valid\"])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, data in enumerate(val_data_loader):\n",
    "                inputs, labels = data[\"im\"].to(device), data[\"labels\"].to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                _, index = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct_preds += (index == labels).sum().item()\n",
    "\n",
    "                validation += val_loss.item()\n",
    "\n",
    "            val_acc = 100 * (correct_preds / total)\n",
    "\n",
    "            print(\"Validation Loss : {:.5f}\".format(validation / dataset_size[\"valid\"]))\n",
    "            print(\"Validation Accuracy is: {:.2f}%\".format(val_acc))\n",
    "\n",
    "            if best_acc < val_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model, \"./saved_model_{:.2f}.pt\".format(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLRIDxb5ERoV"
   },
   "outputs": [],
   "source": [
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds)\n",
    "    ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds)])\n",
    "\n",
    "train_dataset = FlowerDataset(annotations='training.csv',\n",
    "                                   data_path='./flower/train',\n",
    "                                   num_classes=102,\n",
    "                                   transform=train_transforms,\n",
    "                                   mapping=\"flower/data_encoding.csv\")\n",
    "\n",
    "val_dataset = FlowerDataset(annotations='./validation.csv',\n",
    "                              data_path='./flower/valid',\n",
    "                              num_classes=102,\n",
    "                              transform=val_transforms,\n",
    "                              mapping=\"flower/data_encoding.csv\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "data_loader = {\"train\" : train_loader, \"valid\": val_loader}\n",
    "len_dict = {\"train\" : len(train_dataset), \"valid\" : len(val_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKs3wDOaDmc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size 6549\n",
      "Validation Data Size 818\n",
      "Epoch Number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f5718290e80>>Exception ignored in: \n",
      "<bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f5718290e80>>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    Traceback (most recent call last):\n",
      "w.join()\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "        assert self._parent_pid == os.getpid(), 'can only join a child process'self._shutdown_workers()\n",
      "\n",
      "AssertionError: can only join a child process\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "100%|██████████| 103/103 [11:56<00:00,  6.96s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.03449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f5718290e80>>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "<bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f5718290e80>>    self._shutdown_workers()\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "        w.join()self._shutdown_workers()\n",
      "\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "      File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "w.join()    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "  File \"/home/harsha/miniconda3/envs/pt_36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "AssertionError    : assert self._parent_pid == os.getpid(), 'can only join a child process'can only join a child process\n",
      "AssertionError\n",
      ": can only join a child process\n",
      "100%|██████████| 13/13 [00:27<00:00,  2.09s/it]\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.01936\n",
      "Validation Accuracy is: 73.96%\n",
      "Epoch Number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [11:39<00:00,  6.79s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.02719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:28<00:00,  2.16s/it]\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.01428\n",
      "Validation Accuracy is: 79.95%\n",
      "Epoch Number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [11:30<00:00,  6.70s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.02345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:27<00:00,  2.14s/it]\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.01185\n",
      "Validation Accuracy is: 82.76%\n",
      "Epoch Number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [11:32<00:00,  6.72s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.02125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:27<00:00,  2.15s/it]\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.00981\n",
      "Validation Accuracy is: 86.31%\n",
      "Epoch Number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [11:33<00:00,  6.73s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.01979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:27<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.00885\n",
      "Validation Accuracy is: 86.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "train_model(model=model, data_loaders=data_loader, optimizer=optimizer, num_epochs=5, dataset_size=len_dict, criterion=nn.NLLLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1WaA6Fqcc_M"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds)\n",
    "    ])\n",
    "\n",
    "test_dataset = FlowerDataset(annotations='./testing.csv',\n",
    "                              data_path='./flower/test',\n",
    "                              num_classes=102,\n",
    "                              transform=test_transform,\n",
    "                             mapping=\"./flower/data_encoding.csv\",\n",
    "                             mode=\"test\")\n",
    "\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oASN5m6Ibn9l"
   },
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    test_model = torch.load(\"./saved_model_86.55.pt\")\n",
    "    \n",
    "    test_model.eval()\n",
    "    tk0 = tqdm.tqdm(test_dataset_loader)\n",
    "    \n",
    "    total = 0\n",
    "    correct_preds = 0\n",
    "    pred_list = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, data in enumerate(tk0):\n",
    "            single_im, label = data[\"im\"].to(device), data[\"labels\"].to(device)\n",
    "            im_name = data[\"im_name\"]\n",
    "            \n",
    "            pred = test_model(single_im)\n",
    "\n",
    "            _, index = torch.max(pred, 1)\n",
    "\n",
    "            total += label.size(0)\n",
    "            correct_preds += (index == label).sum().item()\n",
    "            \n",
    "            pred_list[im_name[0]] = (index+1).item()\n",
    "            \n",
    "    df = pd.DataFrame(pred_list.items(), columns=['file_name', 'class_name'])\n",
    "    with open(\"results.csv\", \"w\") as f:\n",
    "        df.to_csv(f, index=False)\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * (correct_preds / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkZFRcSncgFa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 819/819 [00:41<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           file_name  class_name\n",
      "0    image_05013.jpg          47\n",
      "1    image_04966.jpg          47\n",
      "2    image_04993.jpg          47\n",
      "3    image_00474.jpg          88\n",
      "4    image_00563.jpg          88\n",
      "..               ...         ...\n",
      "814  image_05653.jpg           9\n",
      "815  image_05636.jpg          43\n",
      "816  image_05678.jpg          80\n",
      "817  image_05637.jpg           4\n",
      "818  image_05658.jpg          88\n",
      "\n",
      "[819 rows x 2 columns]\n",
      "Accuracy of the network on the test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "test(test_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_fb56d330-8d2f-4431-90c8-2a69047076e2\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/18?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_fb56d330-8d2f-4431-90c8-2a69047076e2\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "remo_image_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "18d04c743bb4459d8a8235e8846b178e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e193402cc1b4dbe97531c28ac93a8bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec07bf4e45574e9ca39217f19a0adb48",
       "IPY_MODEL_822d18ace03e4637892cf40ae0996e4a"
      ],
      "layout": "IPY_MODEL_18d04c743bb4459d8a8235e8846b178e"
     }
    },
    "2690eec5fed040cd801e83c2f178d068": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "403ac43de7454dd4b4dfdab3a61ffe14": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "822d18ace03e4637892cf40ae0996e4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_403ac43de7454dd4b4dfdab3a61ffe14",
      "placeholder": "​",
      "style": "IPY_MODEL_b37da2626af94b649d19213f38e14d65",
      "value": " 44.7M/44.7M [00:21&lt;00:00, 2.16MB/s]"
     }
    },
    "b37da2626af94b649d19213f38e14d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca38e79005dd4612ae97645c53113ae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ec07bf4e45574e9ca39217f19a0adb48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2690eec5fed040cd801e83c2f178d068",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca38e79005dd4612ae97645c53113ae2",
      "value": 46827520
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
